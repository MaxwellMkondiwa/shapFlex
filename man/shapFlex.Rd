% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/shapFlex.R
\name{shapFlex}
\alias{shapFlex}
\title{Compute symmetric or asymmetric stochastic feature-level Shapley values}
\usage{
shapFlex(
  explain,
  reference = NULL,
  model,
  predict_function,
  target_features = NULL,
  causal = NULL,
  causal_weights = NULL,
  sample_size = 60,
  use_future = FALSE
)
}
\arguments{
\item{explain}{A data.frame of instances to be explained using Shapley values. \code{explain} is passed internally
as a data.frame to \code{predict_function}.}

\item{reference}{Optional. A data.frame with the same format as \code{explain}--with possibly more or fewer rows--of instances
which serve as a reference group against which the Shapley value deviations from \code{explain} are compared. That is,
\code{reference} is used to calculate an average prediction or intercept value. \code{reference} is passed internally
as a data.frame to \code{predict_function}.}

\item{model}{A trained prediction model object used to compute Shapley values. \code{model} is passed internally to \code{predict_function}.}

\item{predict_function}{A \code{predict()}-type wrapper function that takes 2 required positional arguments--(1) the trained model from \code{model}
and (2) a data.frame of instances with the same format as \code{explain}. For numeric outcomes, the function should \code{return()} a
1-column data.frame of model predictions; the column name does not matter.}

\item{target_features}{Optional. A character vector that is a subset of feature names in \code{explain} for which Shapley values will be computed.
For high-dimensional models, selecting a subset of interesting features may dramatically speed up computation time. The default behavior is
to return Shapley values for all instances and features in \code{explain}.}

\item{causal}{Optional. A list of 1 or more formulas that specify a causal direction for computing asymmetric Shapley values. For example,
\code{list(x1 ~ x2 + x3)} or \code{list(formula(x1 ~ x2 + x3))} computes Shapley values for \code{x_1} after conditioning on
the true/actual values of \code{x2} and \code{x3} for the instance being explained. Only 1 feature is allowed on the left hand side
of the formula, and only 1 formula is allowed per left hand side feature i.e., no duplicated causal constraints for a target feature.}

\item{causal_weights}{Optional. A numeric vector of \code{length(causal)} with weights between 0 and 1 that specifies the strength of
the causal asymmetric Shapley values. A weight of 1--the default if \code{causal_weights = NULL}--estimates a pure causal effect where the
instance to be explained is always conditioned on its true/actual values in the Monte Carlo sampling (e.g., Shapley values for \code{x1}
are based on the instance's true \code{x2} and \code{x3}). A weight of .5 is equivalent to the symmetric Shapley value
calculation--within sampling error--and represents the case where the researcher is uncertain as to whether or not \code{x2} and
\code{x_3} causally precede or follow \code{x1}.}

\item{sample_size}{A numeric vector of length 1 giving the number of Monte Carlo samples used to compute the stochastic Shapley values for
each feature.}

\item{use_future}{Boolean. If \code{TRUE}, the \code{future} package is used to calculate Shapley values in parallel across \code{sample_size}.}
}
\value{
A data.frame with class \code{shapFlex} of the feature-level Shapley values for all instaces in \code{explain}.
}
\description{
This function uses user-defined trained models and prediction functions to compute approximate Shapley values for
single models. Shapley values can be calculated for a subset of model features which reduces the
typically expensive computation of approximate Shapley values in high-dimensional models.
}
